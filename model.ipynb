{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements needed\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torchvision\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm \n",
    "import torchvision.models as models\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GPU if applicable\n",
    "print(torch.cuda.is_available())\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataset + Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Download the CIFAR-100 dataset (downloads only first time running cell)\n",
    "train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_loop(loss_func, optimizer, epochs, train_dataloader, test_dataloader, model):\n",
    "    # variables needed for metrics later\n",
    "    train_losses = []\n",
    "    test_losses = 0\n",
    "    train_accuracy = []\n",
    "    test_accuracy = 0\n",
    "    start_time_train = time.time()\n",
    "    ############################ Train Loop ############################\n",
    "    for epoch in range(epochs):\n",
    "        # variables needed for metrics later\n",
    "        train_size = len(train_dataloader.dataset)\n",
    "        # makes sure to set model to train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_num_batches = len(train_dataloader)\n",
    "        # Just to help with keep track of how long it taking\n",
    "        train_loadbar = tqdm(train_dataloader, total=train_num_batches)\n",
    "        for batch, (X, labels) in enumerate(train_loadbar):\n",
    "            # Make sure values are on correct device\n",
    "            X = X.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Model pred + loss\n",
    "            pred = model(X)\n",
    "            loss = loss_func(pred, labels)\n",
    "\n",
    "            # Backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute metrics\n",
    "            train_loss+=loss.item()\n",
    "            train_correct+=(pred.argmax(axis = 1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "            # Update the loading bar    \n",
    "            train_loadbar.set_description(f'Epoch [{epoch + 1}/{epochs}]')\n",
    "            train_loadbar.set_postfix(train_loss=train_loss/(batch + 1), train_accuracy=train_correct/train_size)\n",
    "\n",
    "\n",
    "        # Compute metrics\n",
    "        train_losses.append(train_loss/train_num_batches)\n",
    "        train_accuracy.append(train_correct/train_size)\n",
    "\n",
    "    end_time_train = time.time()\n",
    "    train_time = end_time_train - start_time_train\n",
    "    ############################ Train Loop ############################\n",
    "    \n",
    "    ############################ Test Loop #############################\n",
    "    test_size = len(test_dataloader.dataset)\n",
    "    test_num_batches = len(test_dataloader)\n",
    "    # makes sure to set model to eval\n",
    "    model.eval()\n",
    "    # variables needed for metrics later\n",
    "    start_time_test = time.time()\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, labels in test_dataloader:\n",
    "            # Make sure values are on correct device\n",
    "            X = X.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Model pred + loss\n",
    "            pred = model(X)\n",
    "            loss = loss_func(pred, labels)\n",
    "\n",
    "            # Compute metrics\n",
    "            test_loss+=loss.item()\n",
    "            test_correct+=(pred.argmax(axis = 1) == labels).type(torch.float).sum().item()\n",
    "        # Compute metrics\n",
    "        test_losses = test_loss/test_num_batches\n",
    "        test_accuracy = test_correct/test_size\n",
    "    \n",
    "    end_time_test = time.time()\n",
    "    test_time = end_time_test - start_time_test\n",
    "    ############################ Test Loop #############################\n",
    "\n",
    "    return train_accuracy, train_losses, test_accuracy, test_losses, train_time, test_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training/Testing Loop (Default Hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compact high-level loop that runs everything and allows modification of all variables\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained = True)\n",
    "# Make 10 class classifier\n",
    "model.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
    "model.to(device)\n",
    "############################################# HYPER PARAMS #############################################\n",
    "batch_size = 64\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "lr = .0001\n",
    "weight_decay = .0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "epochs = 30\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=epochs/3, gamma=.5)\n",
    "############################################# HYPER PARAMS #############################################\n",
    "train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size)\n",
    "train_accuracy, train_losses, test_accuracy, test_losses, train_time, test_time = train_test_loop(loss_func, optimizer, epochs, train_dataloader, test_dataloader, model)\n",
    "# Print results to table\n",
    "data = [train_time, test_time, train_accuracy[-1], test_accuracy, 64, .0001]\n",
    "torch.save(model.state_dict(), f'models/Default_Model.pth')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training/Testing Loop (Altered Hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compact high-level loop that runs everything and allows modification of all variables + make pd dataframe to store all information\n",
    "columns = [\"Train_Time\", \"Test_Time\", \"Train_Acc\", \"Test_Acc\", \"Batch\", \"LR\"]\n",
    "df = pd.DataFrame(columns = columns)\n",
    "for l in [.0002, .00005]:\n",
    "    for b in [16, 32, 128, 256, 512]:\n",
    "        model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained = True)\n",
    "        # Make 10 class classifier\n",
    "        model.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
    "        model.to(device)\n",
    "        ############################################# HYPER PARAMS #############################################\n",
    "        batch_size = b\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        lr = l\n",
    "        weight_decay = .0001\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        epochs = 30\n",
    "        #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=epochs/3, gamma=.5)\n",
    "        ############################################# HYPER PARAMS #############################################\n",
    "        train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size)\n",
    "        train_accuracy, train_losses, test_accuracy, test_losses, train_time, test_time = train_test_loop(loss_func, optimizer, epochs, train_dataloader, test_dataloader, model)\n",
    "        # Add results to table\n",
    "        data = [train_time, test_time, train_accuracy[-1], test_accuracy, b, l]\n",
    "        row = pd.DataFrame([data], columns=columns)\n",
    "        df = pd.concat([df, row], ignore_index=True)\n",
    "        print(data)\n",
    "        torch.save(model.state_dict(), f'models/model_{l}_{b}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_directory = 'models/'\n",
    "model_files = [f for f in os.listdir(models_directory) if f.endswith('.pth')]\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test, batch_size=64)\n",
    "class_names = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n",
    "\n",
    "for model_path in model_files:\n",
    "    path = os.path.join(models_directory, model_path)\n",
    "    model_weights = torch.load(path)\n",
    "\n",
    "    model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1')\n",
    "    model.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
    "    model.load_state_dict(model_weights)\n",
    "    model.to(device)\n",
    "\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "\n",
    "    print(path)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            \n",
    "            outputs = model(inputs.to(device))\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predicted_labels.extend(preds.cpu().detach().numpy())\n",
    "            true_labels.extend(labels.cpu().detach().numpy())\n",
    "\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Plot the confusion matrix using Seaborn\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names, cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results.csv\")\n",
    "\n",
    "# Group data by LR (since we have 2 different LRs)\n",
    "grouped = df.groupby('LR')\n",
    "\n",
    "# Create plots for each LR\n",
    "for lr, group in grouped:\n",
    "    _, ax1 = plt.subplots()\n",
    "\n",
    "    ax1.set_xlabel('Batch Size')\n",
    "    # Left y-axis\n",
    "    ax1.set_ylabel('Accuracy(%)', color='blue')\n",
    "    ax1.plot(group['Batch'], group['Test_Acc']*100, marker='o', color='blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "    # Right y-axis\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Training Time (seconds)', color='red')\n",
    "    ax2.plot(group['Batch'], group['Train_Time'], marker='o', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "    x_ticks_values = [16, 32, 128, 256, 512]\n",
    "    ax1.set_xticks(x_ticks_values)\n",
    "\n",
    "    plt.title(f'Accuracy/Training Time vs. Batch Size for (LR={lr})')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through different values of size and k\n",
    "train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Create a mapping using the values given by CIFAR-10 website\n",
    "class_mapping = [(\"Airplane\" , 0), (\"Automobile\" , 1), (\"Bird\" , 2), (\"Cat\" , 3), (\"Deer\" , 4), (\"Dog\" , 5), (\"Frog\" , 6), (\"Horse\" , 7), (\"Ship\" , 8), (\"Truck\" , 9)]\n",
    "# number of categories\n",
    "num_categories = len(class_mapping)\n",
    "\n",
    "# 5 images per column\n",
    "fig_width = 5 * num_categories * 2\n",
    "fig_height = num_categories * 2\n",
    "\n",
    "# Generate and display 5 random images per category as one row\n",
    "for class_name, label in class_mapping:\n",
    "    category_images = [img for img, l in train if l == label]\n",
    "    random_indices = random.sample(range(len(category_images)), 5)\n",
    "    \n",
    "    # Adjust figure size for displaying images\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    for i, idx in enumerate(random_indices):\n",
    "        img = category_images[idx]\n",
    "        # expects H x W x C images not C x H x W\n",
    "        img = np.transpose(img, (1, 2, 0)) \n",
    "        plt.subplot(1, num_categories * 5, i + 1)\n",
    "        plt.imshow(img)\n",
    "        if i == 0:  # only for first image prevents\n",
    "            plt.title(class_name)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Test Scenario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_1_test(k_dataload, model):\n",
    "    preds_vec = None\n",
    "    preds = None\n",
    "    # makes sure to set model to eval\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, labels in k_dataload:\n",
    "            # Make sure values are on correct device\n",
    "            X = X.to(device)\n",
    "\n",
    "            # Model pred\n",
    "            preds_vec = model(X)\n",
    "\n",
    "            preds = preds_vec.argmax(axis = 1)\n",
    "\n",
    "    return preds_vec, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "k_folder = torchvision.datasets.ImageFolder(root='k_images', transform=transform)\n",
    "k_dataload = torch.utils.data.DataLoader(k_folder, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on default model\n",
    "model_weights = torch.load(\"models/Default_Model.pth\")\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1')\n",
    "model.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
    "model.load_state_dict(model_weights)\n",
    "model.to(device)\n",
    "preds_vec, preds = k_1_test(k_dataload, model)\n",
    "\n",
    "print(preds_vec)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Shaan/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "c:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Using cache found in C:\\Users\\Shaan/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "c:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet50 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "resnet18 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "vgg11 = torchvision.models.vgg11(pretrained=True)\n",
    "vgg19 = torchvision.models.vgg19(pretrained=True)\n",
    "mobilenet = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "mobilenet.classifier[1] = nn.Linear(mobilenet.classifier[1].in_features, 10)\n",
    "\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, 10)\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 10)\n",
    "\n",
    "vgg11.classifier[6] = nn.Linear(vgg11.classifier[6].in_features, 10)\n",
    "vgg19.classifier[6] = nn.Linear(vgg19.classifier[6].in_features, 10)\n",
    "models = [resnet18, resnet50, mobilenet, vgg11, vgg19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test other models\n",
    "device = 'cuda'\n",
    "pred_vec_list = []\n",
    "preds_list = []\n",
    "for model in models:\n",
    "    model.to(device)\n",
    "    ############################################# HYPER PARAMS #############################################\n",
    "    batch_size = 64\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    lr = .001\n",
    "    weight_decay = .0001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    epochs = 10\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=epochs/3, gamma=.5) \n",
    "    ############################################# HYPER PARAMS #############################################\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size)\n",
    "    train_accuracy, train_losses, test_accuracy, test_losses, train_time, test_time = train_test_loop(loss_func, optimizer, epochs, train_dataloader, test_dataloader, model)\n",
    "    # Add results to table\n",
    "    data = [train_time, test_time, train_accuracy[-1], test_accuracy]\n",
    "    preds_vec, preds = k_1_test(k_dataload, model)\n",
    "    pred_vec_list.append(preds_vec)\n",
    "    preds_list.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
